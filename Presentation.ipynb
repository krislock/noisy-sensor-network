{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6d359f9",
   "metadata": {},
   "source": [
    "$\n",
    "\\DeclareMathOperator{\\tr}{tr}\n",
    "\\DeclareMathOperator{\\rank}{rank}\n",
    "\\DeclareMathOperator{\\Diag}{Diag}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef843589",
   "metadata": {},
   "source": [
    "---\n",
    "<center>\n",
    "    \n",
    "# Sensor Network Localization with Noisy Distance Measurements\n",
    "    \n",
    "## Nathan Krislock\n",
    "### Department of Mathematical Sciences\n",
    "### Northern Illinois University, USA\n",
    "    \n",
    "### [Mini-symposium on Sensor Network Localization and Dynamical Distance Geometry](http://www.fields.utoronto.ca/activities/20-21/constraint-sensor), [The Fields Institute](http://www.fields.utoronto.ca/), Canada\n",
    "    \n",
    "### May 21, 2021\n",
    "    \n",
    "#### Joint work with Dmitriy Drusvyatskiy, Yuen-Lam Voronin, and Henry Wolkowicz \n",
    "    \n",
    "> Dmitriy Drusvyatskiy, Nathan Krislock, Yuen-Lam Voronin, and Henry Wolkowicz. Noisy Euclidean distance realization: Robust facial reduction and the Pareto frontier. SIAM Journal on Optimization, 27(4):2301–2331, 2017. [https://doi.org/10.1137/15M103710X](https://doi.org/10.1137/15M103710X)\n",
    " \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc457efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"functions.jl\")\n",
    "pltsize=(600,600);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c371895e",
   "metadata": {},
   "source": [
    "---\n",
    "# Sensor network localization\n",
    "---\n",
    "\n",
    "- Find $p_1,\\ldots,p_n \\in \\mathbb{R}^r$ satisfying:\n",
    "\n",
    "$$\n",
    "\\|p_i - p_j\\| = d_{ij}, \\quad ij \\in E,\n",
    "$$\n",
    "\n",
    "$$\n",
    "p_{n-m+i} = a_i, \\quad i=1,\\ldots,m.\n",
    "$$\n",
    "\n",
    "- $p_1,\\ldots,p_{n-m}$ are *sensor positions* and $p_{n-m+1},\\ldots,p_n$ are *anchor positions*\n",
    "\n",
    "- $a_1,\\ldots,a_m \\in \\mathbb{R}^r$ are given anchor positions\n",
    "\n",
    "- $\\| \\cdot \\|$ is the Euclidean norm\n",
    "\n",
    "- $E$ is set of edges in a graph $G = (V,E)$ where $V = \\{1,\\ldots,n\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af276951",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "\n",
    "Random.seed!(2105)\n",
    "\n",
    "R = 0.3\n",
    "\n",
    "n, m, r = 50, 5, 2\n",
    "\n",
    "Strue, A = genprob(n, m, r)\n",
    "\n",
    "Ptrue = [Strue; A]\n",
    "\n",
    "E, dtrue = edges(Ptrue, R, m)\n",
    "\n",
    "@show length(E)\n",
    "\n",
    "plot_network(Ptrue, E, m); plot!(size=pltsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8d419c",
   "metadata": {},
   "source": [
    "---\n",
    "# Euclidean distance matrices\n",
    "---\n",
    "\n",
    "- An $n \\times n$ matrix $D$ is a *Euclidean distance matrix (EDM)* if\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\label{eq:EDM}\n",
    "\t\\exists p_1,\\ldots,p_n \\in \\mathbb{R}^r : D_{ij} = \\|p_i - p_j\\|^2.\n",
    "\\end{equation}\n",
    "\n",
    "- The *embedding dimension* of $D$ is\n",
    "\n",
    "$$\n",
    "\\dim(D) = \\min\\{ k : \\text{\\eqref{eq:EDM} holds} \\}.\n",
    "$$\n",
    "\n",
    "- $\\mathcal{E}^n =$ the set of all $n \\times n$ EDMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120e111b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Let $p_1,\\ldots,p_n \\in \\mathbb{R}^r$ and $D$ be their EDM\n",
    "\n",
    "- Let $X \\in \\mathcal{S}^n$ be the *Gram matrix*:\n",
    "\n",
    "$$\n",
    "X_{ij} = p_i^T p_j, \\quad \\forall ij\n",
    "$$\n",
    "\n",
    "- Then $X$ is a semidefinite matrix: $X \\in \\mathcal{S}^n_+$\n",
    "\n",
    "$$\n",
    "D_{ij} = X_{ii} + X_{jj} - 2X_{ij} =: K(X)_{ij}\n",
    "$$\n",
    "\n",
    "- $K(\\mathcal{S}^n_+) = \\mathcal{E}^n$\n",
    "\n",
    "- $e \\in \\mathbb{R}^n$ is the vector of all ones\n",
    "\n",
    "- $K$ is a linear bijection between the *centered* semidefinite matrices\n",
    "\n",
    "    \\begin{equation*}\n",
    "    \\mathcal{S}^n_{c,+} = \\left\\{X \\in \\mathcal{S}^n_+ : X e = 0\\right\\}\n",
    "    \\end{equation*}\n",
    "\n",
    "  and $\\mathcal{E}^n$\n",
    "  \n",
    "- $D = K(X)$ and $X \\in \\mathcal{S}^n_{c,+}$ $\\implies$ $\\dim(D) = \\rank(X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6b053",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- $P \\colon \\mathcal{S}^n \\to \\mathbb{R}^E$ defined by\n",
    "\n",
    "$$\n",
    "P(M)_{ij} = M_{ij}, \\quad ij \\in E\n",
    "$$\n",
    "\n",
    "- $d \\in \\mathbb{R}^E$ is the vector of **squared distances**\n",
    "\n",
    "- Sensor network localization is EDM completion\n",
    "    \n",
    "\\begin{array}{ll}\n",
    "    \\text{minimize}   & \\rank X  \\\\\n",
    "    \\text{subject to} & P \\circ K(X) = d \\\\\n",
    "                      & Xe = 0 \\\\\n",
    "                      & X \\succeq 0\n",
    "\\end{array}\n",
    "    \n",
    "- Factor $X = PP^T$ where $P \\in \\mathbb{R}^{n \\times r}$ and $r = \\rank X$\n",
    "\n",
    "- Align anchors by solving a Procrustes problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2bf0ae",
   "metadata": {},
   "source": [
    "---\n",
    "# Multiplicative noise model\n",
    "---\n",
    "\n",
    "- Noiseless squared distances $d \\in \\mathbb{R}^E$\n",
    "\n",
    "- Noisy squared distances $\\bar{d} \\in \\mathbb{R}^E$\n",
    "\n",
    "$$\n",
    "\\bar{d}_{ij} = (1 + p\\varepsilon_{ij})^2 d_{ij}\n",
    "$$\n",
    "\n",
    "- $\\varepsilon_{ij} \\sim \\mathcal{N}(0, 1)$\n",
    "\n",
    "$$\n",
    "\\frac{\\bar{d}_{ij} - d_{ij}}{d_{ij}} \\approx 2p \\varepsilon_{ij}\n",
    "$$\n",
    "\n",
    "- `noise_stats` experiment:\n",
    "$$\n",
    "\\mathtt{error} = \\left\\|\\bar{d} - d\\right\\|,\n",
    "\\qquad\n",
    "\\mathtt{std} = \\text{std}\\left(\\left[\\frac{\\bar{d}_{ij} - d_{ij}}{d_{ij}}\\right]_{ij \\in E}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64afdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.2\n",
    "\n",
    "errors, stds = noise_stats(E, dtrue, p, n, m, N=100_000)\n",
    "    \n",
    "@show mean(errors)\n",
    "@show mean(stds)\n",
    "\n",
    "plot(legend=:topright)\n",
    "histogram!(errors, alpha=0.5, normalize=:probability, label=\"error\")\n",
    "histogram!(stds, alpha=0.5, normalize=:probability, label=\"std\")\n",
    "vline!([mean(errors)], c=:blue, label=\"mean error\")\n",
    "vline!([mean(stds)], c=:red, label=\"mean std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81fa223",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error(p; N=10_000) = noise_stats(E, dtrue, p, n, m; N=N)[1] |> mean\n",
    "\n",
    "mean_error(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f02c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 0.0, 0.5\n",
    "ps = range(a, b, length=100)\n",
    "@time mean_errors = mean_error.(ps; N=1000)\n",
    "\n",
    "mean_errors[end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d64a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(legend=:topleft, ylable=L\"y\", xlabel=L\"p\", size=pltsize)\n",
    "plot!(ps, mean_errors, label=\"mean errors\")\n",
    "plot!(t -> 1.8t, a, b, label=L\"y = 1.8p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7974151",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.2\n",
    "\n",
    "dnoisy = add_noise(E, dtrue, p, n, m)\n",
    "\n",
    "ainds = inter_anchor(E, n, m)\n",
    "yinds = ainds .|> !\n",
    "\n",
    "tdy = dtrue[yinds]\n",
    "ndy = dnoisy[yinds]\n",
    "\n",
    "@show p\n",
    "@show std((ndy - tdy)./tdy)\n",
    "@show norm(ndy - tdy)\n",
    "\n",
    "bins = range(0.0, 0.5, length=20)\n",
    "plot(legend=:topright, xlabel=\"distance\", ylabel=\"fraction\")\n",
    "histogram!(sqrt.(tdy), bins=bins, alpha=0.5, label=\"noiseless\", normalize=:probability)\n",
    "histogram!(sqrt.(ndy), bins=bins, alpha=0.5, label=\"noisy\", normalize=:probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38baac0",
   "metadata": {},
   "source": [
    "---\n",
    "# Minimizing the rank\n",
    "---\n",
    "\n",
    "- We want to find a feasible $X$ with minimal rank.\n",
    "\n",
    "\\begin{array}{ll}\n",
    "    \\text{minimize}   & \\rank X  \\\\\n",
    "    \\text{subject to} & \\|P \\circ K(X) - \\bar{d}\\| \\le \\sigma \\\\\n",
    "                      & Xe = 0 \\\\\n",
    "                      & X \\succeq 0\n",
    "\\end{array}\n",
    "\n",
    "- A common convex relaxation for rank minimization is to minimize the **nuclear norm** of $X$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\|X\\|_* = \\sum_{i=1}^n \\sigma_i(X)\n",
    "\\end{equation*}\n",
    "\n",
    "- Since $X \\succeq 0$, we have\n",
    "\n",
    "\\begin{equation*}\n",
    "\\|X\\|_* = \\tr X\n",
    "\\end{equation*}\n",
    "\n",
    "- Since $Xe = 0$, we also have\n",
    "\n",
    "$$\n",
    "\\tr X = \\frac{1}{2n} \\sum_{i,j=1}^n \\|p_i - p_j\\|^2\n",
    "$$\n",
    "\n",
    "- Minimizing the trace pulls the sensors together\n",
    "\n",
    "\\begin{array}{ll}\n",
    "    \\text{minimize}   & \\tr X  \\\\\n",
    "    \\text{subject to} & \\|P \\circ K(X) - \\bar{d}\\| \\le \\sigma \\\\\n",
    "                      & Xe = 0 \\\\\n",
    "                      & X \\succeq 0\n",
    "\\end{array}\n",
    "\n",
    "- Maximizing the trace pushes the sensor away from each other\n",
    "\n",
    "\\begin{array}{ll}\n",
    "    \\text{maximize}   & \\tr X  \\\\\n",
    "    \\text{subject to} & \\|P \\circ K(X) - \\bar{d}\\| \\le \\sigma \\\\\n",
    "                      & Xe = 0 \\\\\n",
    "                      & X \\succeq 0\n",
    "\\end{array}\n",
    "\n",
    "- We expect that maximizing the trace will flatten the graph and give us a low rank $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52682b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "σ = mean_error(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc981c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "σ = 0.40\n",
    "\n",
    "Xmin = opt_trace(E, dnoisy, σ, n, m; sense=:min)\n",
    "Xmax = opt_trace(E, dnoisy, σ, n, m; sense=:max)\n",
    "\n",
    "d̄min = K(Xmin, E)\n",
    "d̄max = K(Xmax, E)\n",
    "\n",
    "@show σ\n",
    "println()\n",
    "@show norm(d̄min - dnoisy)\n",
    "@show norm(d̄max - dnoisy)\n",
    "println()\n",
    "@show norm(d̄min - dtrue)\n",
    "@show norm(d̄max - dtrue);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71a549d",
   "metadata": {},
   "source": [
    "---\n",
    "# Low-rank projection\n",
    "---\n",
    "\n",
    "- We project the optimal $X$ onto the set of rank $r$ matrices to get $X_r = PP^T$ with $P \\in \\mathbb{R}^{n \\times r}$\n",
    "\n",
    "- The rows of $P$ are the estimated sensor and anchor positions in $\\mathbb{R}^r$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c98b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "P̄min = low_rank_soln(Xmin)\n",
    "P̄max = low_rank_soln(Xmax)\n",
    "\n",
    "d̄min2 = K(P̄min*P̄min', E)\n",
    "d̄max2 = K(P̄max*P̄max', E)\n",
    "\n",
    "println(\"\\nProjected solution:\")\n",
    "println()\n",
    "@show norm(d̄min2 - dnoisy)\n",
    "@show norm(d̄max2 - dnoisy)\n",
    "println()\n",
    "@show norm(d̄min2 - dtrue)\n",
    "@show norm(d̄max2 - dtrue);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b92492d",
   "metadata": {},
   "source": [
    "---\n",
    "# Align anchors\n",
    "---\n",
    "\n",
    "- The anchor positions $B$ in the matrix $P$ are likely not correct\n",
    "\n",
    "- First we center $B$ and $A$ by substracting their mean points\n",
    "\n",
    "- We then align $B$ with $A$ by solving the *Procrustes problem*:\n",
    "\n",
    "\\begin{array}{ll}\n",
    "    \\text{minimize}   & \\|B Q - A\\|_F  \\\\\n",
    "    \\text{subject to} & Q^T Q = I. \\\\\n",
    "\\end{array}\n",
    "\n",
    "- $Q = UV^T$ is optimal where $B^T A = U \\Sigma V^T$ is the singular value decomposition of $B^T A$\n",
    "\n",
    "- After replacing $P$ with $PQ$, we add the mean of $A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d1d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "P̄min_aligned = align_anchors(A, P̄min, m)\n",
    "P̄max_aligned = align_anchors(A, P̄max, m);\n",
    "\n",
    "lims = (-0.8, 0.8)\n",
    "plt1 = plot_network(P̄min, E, m, lims=lims, legend=:none);         title!(plt1, \"Min trace\")\n",
    "plt2 = plot_network(P̄max, E, m, lims=lims, legend=:none);         title!(plt2, \"Max trace\")\n",
    "plt3 = plot_network(Ptrue, E, m, lims=lims, legend=:none);        title!(plt3, \"True positions\")\n",
    "plt4 = plot_network(P̄max_aligned, E, m, lims=lims, legend=:none); title!(plt4, \"Max trace aligned\")\n",
    "\n",
    "plot(plt1, plt2, plt3, plt4, size=pltsize, titlefontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb912dc",
   "metadata": {},
   "source": [
    "---\n",
    "# Refine positions\n",
    "---\n",
    "\n",
    "- Based on the multiplicative noise model, the *maximum likelihood* solution is given by the optimal solution of the least-squares problem\n",
    "\n",
    "\\begin{array}{ll}\n",
    "    \\text{minimize}   & \\sum_{ij \\in E} v_{ij}^2  \\\\\n",
    "    \\text{subject to} & \\|p_i - p_j\\|^2 = (1 + v_{ij})^2 \\bar{d}_{ij}, \\quad ij \\in E \\\\\n",
    "    & p_1,\\ldots,p_n \\in \\mathbb{R}^r\n",
    "\\end{array}\n",
    "\n",
    "- Since this problem would be challenging to solve, we instead consider the related nonlinear least-squares problem\n",
    "\n",
    "$$\n",
    "q(P) = \\sum_{ij \\in E} \\left(\\frac{\\|p_i - p_j\\| - \\bar{d}_{ij}}{\\bar{d}_{ij}}\\right)^2\n",
    "$$\n",
    "\n",
    "- The points in $P$ obtained from the maximum trace semidefinite relaxation are used as a good starting point for a gradient descent  minimization of $q(P)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88258ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "S̄0 = P̄max_aligned[1:n-m,:]\n",
    "\n",
    "qS, dS = q(S̄0), q'(S̄0)\n",
    "qS, -dot(dS,dS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c01aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "S̄100 = refine(S̄0, Strue, N=100)\n",
    "P̄100 = [S̄100; A];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff96a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "S̄ = refine(S̄0, Strue, N=N)\n",
    "P̄ = [S̄; A];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc0497",
   "metadata": {},
   "outputs": [],
   "source": [
    "lims = (-0.6, 0.6)\n",
    "plt1 = plot_network([S̄0; A], E, m, lims=lims, legend=:none); title!(plt1, \"Max trace aligned\")\n",
    "plt2 = plot_network(Ptrue, E, m, lims=lims, legend=:none);   title!(plt2, \"True positions\")\n",
    "plt3 = plot_network(P̄100, E, m, lims=lims, legend=:none);    title!(plt3, \"Refined (k=100)\")\n",
    "plt4 = plot_network(P̄, E, m, lims=lims, legend=:none);       title!(plt4, \"Refined (k=$N)\")\n",
    "plot(plt1, plt2, plt3, plt4, size=pltsize, titlefontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c84e95f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lims=(-0.6, 0.6)\n",
    "plt1 = plot_errors(Ptrue, S̄0, m, lims=lims, legend=:none);    title!(plt1, \"Max trace aligned\")\n",
    "plt2 = plot_errors(Ptrue, Strue, m, lims=lims, legend=:none); title!(plt2, \"True positions\")\n",
    "plt3 = plot_errors(Ptrue, S̄100, m, lims=lims, legend=:none);  title!(plt3, \"Refined (k=100)\")\n",
    "plt4 = plot_errors(Ptrue, S̄, m, lims=lims, legend=:none);     title!(plt4, \"Refined (k=$N)\")\n",
    "plot(plt1, plt2, plt3, plt4, size=pltsize, titlefontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e1df55",
   "metadata": {},
   "source": [
    "---\n",
    "# Pareto frontier\n",
    "\n",
    "---\n",
    "\n",
    "- A famous example of a *Pareto frontier* is the [efficient frontier](https://en.wikipedia.org/wiki/Efficient_frontier) in *portfolio optimization*. \n",
    "\n",
    "- An investment portfolio is on the efficient frontier if there is no other portfolio with a higher expected return at the same level of risk.\n",
    "\n",
    "![frontier](https://upload.wikimedia.org/wikipedia/commons/e/e1/Markowitz_frontier.jpg)\n",
    "\n",
    "- This efficient frontier can be parametrized by risk or by expected return."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5306e076",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- For our problem, a matrix $X$ is on the *Pareto frontier* if it is an optimal solution of the maximum trace problem.\n",
    "\n",
    "\\begin{array}{lll}\n",
    "    \\psi(\\sigma) =\n",
    "    & \\text{maximize}   & \\tr X  \\\\\n",
    "    & \\text{subject to} & \\|P \\circ K(X) - d\\| \\le \\sigma \\\\\n",
    "    &                   & Xe = 0 \\\\\n",
    "    &                   & X \\succeq 0\n",
    "\\end{array}\n",
    "\n",
    "- This Pareto frontier is parametrized by the error level $\\sigma$, but can also be parametrized by the trace level $\\tau$.\n",
    "\n",
    "- That is, $X$ is on the Pareto frontier if it is an optimal solution of the minimum error problem.\n",
    "\n",
    "\\begin{array}{lll}\n",
    "    \\phi(\\tau) =\n",
    "    & \\text{minimize}   & \\|P \\circ K(X) - d\\|  \\\\\n",
    "    & \\text{subject to} & \\tr X \\ge \\tau \\\\\n",
    "    &                   & Xe = 0 \\\\\n",
    "    &                   & X \\succeq 0\n",
    "\\end{array}\n",
    "\n",
    "- We can find a solution of the first problem by solving the second problem with $\\tau$ satisfying\n",
    "\n",
    "$$\\phi(\\tau) = \\sigma.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c2e785",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Our approach here is inspired by Pareto frontier approach used in the [SPGL1](https://friedlander.io/spgl1/) solver.\n",
    "\n",
    "> Ewout van den Berg and Michael P. Friedlander. Probing the Pareto frontier for basis pursuit solutions. SIAM Journal on Scientific Computing, 31(2):890–912, 2008. [https://doi.org/10.1137/080714488](https://doi.org/10.1137/080714488)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264bf772",
   "metadata": {},
   "outputs": [],
   "source": [
    "function ϕ(τ)\n",
    "    optimizer = optimizer_with_attributes(\n",
    "        SCS.Optimizer,\n",
    "        \"eps\" => 1e-4,\n",
    "        \"verbose\" => 0)\n",
    "    \n",
    "    model = Model(optimizer)\n",
    "    \n",
    "    @variable(model, X[1:n,1:n], PSD)\n",
    "    @variable(model, t)\n",
    "    \n",
    "    # Minimize norm(K(X,E) - dnoisy)\n",
    "    @objective(model, Min, t)\n",
    "    @constraint(model, [t; K(X,E) - dnoisy] in SecondOrderCone())\n",
    "    \n",
    "    @constraint(model, tr(X) ≥ τ)\n",
    "    @constraint(model, sum(X, dims=2) .== 0)\n",
    "    \n",
    "    optimize!(model)\n",
    "    objective_value(model)\n",
    "end\n",
    "\n",
    "τ = tr(Xmax)\n",
    "σ, ϕ(τ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d0c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 0.5τ, 1.5τ\n",
    "\n",
    "τs = range(a, b, length=50)\n",
    "@time ϕs = ϕ.(τs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(legend=:topleft, xlabel=\"tr(X)\", ylabel=\"error\", size=pltsize)\n",
    "plot!(τs, ϕs, label=\"Pareto frontier\")\n",
    "hline!([σ], label=L\"\\sigma\")\n",
    "scatter!([tr(Xmax)], [norm(K(Xmax,E) - dnoisy)], c=2, label=\"Xmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4fc527",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Finding $\\tau$\n",
    "\n",
    "---\n",
    "\n",
    "- Let $L = P \\circ K$ and define\n",
    "\n",
    "$$f(X) = \\frac12\\|L(X) - d\\|^2, \\qquad \n",
    "\\mathcal{D} = \\big\\{ X \\succeq 0 : \\tr X \\ge 1, Xe = 0\\big\\}$$\n",
    "\n",
    "- This problem has the same optimal set as the minimum error problem\n",
    "\n",
    "$$h(\\tau) = \\min\\big\\{f(X) : X \\in \\tau\\mathcal{D}\\big\\}$$\n",
    "\n",
    "- We will use an inexact-Newton algorithm for solving\n",
    "\n",
    "$$\n",
    "h(\\tau) = \\frac{1}{2}\\sigma^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40687e9d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- The function $f$ is convex and smooth with\n",
    "\n",
    "$$\\nabla f(X) = L^*(L(X) - d)$$\n",
    "\n",
    "- The adjoint of $L$ is $L^* = K^* \\circ P^*$\n",
    "\n",
    "- The adjoint of $P \\colon \\mathcal{S}^n \\to \\mathbb{R}^E$ is\n",
    "\n",
    "$$P^*(y) = M\n",
    "\\quad \\iff \\quad\n",
    "M_{ij} =\n",
    "\\begin{cases}\n",
    "\\frac{1}{2}y_{ij}, & ij \\in E \\\\\n",
    "0, & ij \\not\\in E\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "- The adjoint of $K \\colon \\mathcal{S}^n \\to \\mathcal{S}^n$ is\n",
    "\n",
    "$$\n",
    "K^*(M) = 2\\big(\\Diag(Me) - M\\big)\n",
    "$$\n",
    "\n",
    "- The matrix $\\nabla f(X)$ will be sparse if the graph $G = (V,E)$ is sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf6e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f(X, E, d) = 1/2*norm(L(X, E) - d)^2\n",
    "\n",
    "∇f(X, E, d) = Ls(L(X, E) - d, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccec952",
   "metadata": {},
   "outputs": [],
   "source": [
    "fval = f(Xmax, E, dnoisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c74096",
   "metadata": {},
   "outputs": [],
   "source": [
    "dX = ∇f(Xmax, E, dnoisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7b3ec9",
   "metadata": {},
   "source": [
    "---\n",
    "# The Frank-Wolfe algorithm\n",
    "---\n",
    "\n",
    "- We use the *Frank-Wolfe algorithm* to approximately solve\n",
    "\n",
    "$$\n",
    "h(\\tau) = \\min\\big\\{ f(X) : X \\in \\tau\\mathcal{D}\\big\\}\n",
    "$$\n",
    "\n",
    "- Given $X_0 \\in \\tau\\mathcal{D}$ and $\\alpha > 1$, we obtain a feasible $X_k$ and bounds $l_k$ and $u_k$ such that\n",
    "\n",
    "$$\n",
    "l_k \\le h(\\tau) \\le f(X_k) = u_k\n",
    "$$\n",
    "\n",
    "- The matrix $X_k$ is never explicitly stored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fecd209",
   "metadata": {},
   "source": [
    "---\n",
    "### The search direction\n",
    "\n",
    "- At iteration $k$, we have $X_k \\in \\tau\\mathcal{D}$\n",
    "\n",
    "- $\\Delta X = S - X_k$ is our search direction, where $S \\in \\tau\\mathcal{D}$ minimizes the first-order approximation of $f$ at $X_k$:\n",
    "\n",
    "$$\n",
    "f(X_k) + \\langle \\nabla f(X_k), S - X_k \\rangle\n",
    "$$\n",
    "\n",
    "- That is, we solve the subproblem\n",
    "\n",
    "$$\n",
    "\\min\\big\\{ \\langle \\nabla f(X_k), S \\rangle : S \\in \\tau\\mathcal{D}\\big\\}\n",
    "$$\n",
    "\n",
    "- The optimal solution of this subproblem is $S = \\tau v v^T$ and the optimal value is $\\tau \\lambda$, where $\\lambda$ is the smallest eigenvalue of $\\nabla f(X_k)$ restricted to $e^\\perp$, and $v$ is the corresponding unit eigenvector\n",
    "\n",
    "- The derivative of the optimal value $\\tau \\lambda$ of the subproblem with respect to $\\tau$ is $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828df911",
   "metadata": {},
   "source": [
    "---\n",
    "### The step length\n",
    "\n",
    "- The step length $\\gamma \\in (0, 1]$ is chosen to minimize $f(X_k + \\gamma \\Delta X)$:\n",
    "\n",
    "$$\n",
    "\\frac{d}{d\\gamma} f(X_k + \\gamma \\Delta X) = \n",
    "\\big\\langle L^*(L(X_k + \\gamma \\Delta X) - d), \\Delta X \\big\\rangle = 0\n",
    "$$\n",
    "\n",
    "- Letting $y := L(X_k) - d$, we have\n",
    "\n",
    "$$\n",
    "\\big\\langle y + \\gamma L(\\Delta X), L(\\Delta X) \\big\\rangle = 0\n",
    "$$\n",
    "\n",
    "- Thus,\n",
    "\n",
    "$$\n",
    "\\gamma = -\\frac{\\langle L(\\Delta X), y\\rangle}{\\|L(\\Delta X)\\|^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08af825f",
   "metadata": {},
   "source": [
    "---\n",
    "### Update\n",
    "\n",
    "- We let \n",
    "\n",
    "$$\n",
    "X_{k+1} = X_k + \\gamma \\Delta X\n",
    "$$\n",
    "\n",
    "- Since $f$ is convex and $X_{k+1} \\in \\tau\\mathcal{D}$, we have\n",
    "\n",
    "$$\n",
    "f(X_k) + \\langle \\nabla f(X_k), \\Delta X \\rangle\n",
    "\\le \\min\\big\\{ f(X) : X \\in \\tau\\mathcal{D}\\big\\} \\le f(X_{k+1})\n",
    "$$\n",
    "\n",
    "- We begin with the valid bounds $l_0 = \\frac{1}{2}\\sigma^2$ and $u_0 = \\infty$\n",
    "\n",
    "$$\n",
    "l_0 \\le h(\\tau) \\le u_0\n",
    "$$\n",
    "\n",
    "- We update the bounds\n",
    "\n",
    "$$\n",
    "l_{k+1} = \\max\\{l_k, f(X_k) + \\langle \\nabla f(X_k), \\Delta X \\rangle\\},\n",
    "\\qquad\n",
    "u_{k+1} = \\min\\{u_k, f(X_{k+1})\\}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc7208e",
   "metadata": {},
   "source": [
    "---\n",
    "### Stopping\n",
    "\n",
    "- We stop the Frank-Wolfe method when\n",
    "\n",
    "$$\n",
    "u_k - \\frac{1}{2}\\sigma^2 \\le \\alpha \\left(l_k - \\frac{1}{2}\\sigma^2\\right)\n",
    "$$\n",
    "\n",
    "- $\\alpha$ is a scalar that is larger than $1$\n",
    "\n",
    "- We have\n",
    "\n",
    "$$\n",
    "0 \\le l_k - \\frac{1}{2}\\sigma^2 \\le h(\\tau) - \\frac{1}{2}\\sigma^2 \\le \\alpha \\left(l_k - \\frac{1}{2}\\sigma^2\\right)\n",
    "$$\n",
    "\n",
    "- We return $l_k$, $u_k$, and the eigenvalue $\\lambda$ to the inexact-Newton method\n",
    "\n",
    "- The function $t \\mapsto l_k + \\lambda(t - \\tau)$ is an affine minorant of $h$\n",
    "\n",
    "$$\n",
    "l_k + \\lambda(t - \\tau) \\le h(t), \\quad \\forall t\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a8145",
   "metadata": {},
   "outputs": [],
   "source": [
    "function FrankWolfe(τ, flb0, d, E, n; α=2.0)\n",
    "\n",
    "    d = copy(dnoisy)\n",
    "\n",
    "    fub = Inf\n",
    "    flb = flb0\n",
    "    λ = NaN\n",
    "    \n",
    "    v = randn(n)\n",
    "    v .-= mean(v)\n",
    "    v .*= sqrt(τ)/norm(v)\n",
    "    LX0 = [(v[e[1]] - v[e[2]])^2 for e in E]\n",
    "    \n",
    "    Xinfo = Dict(:γ=>[1.0], :v=>[v])\n",
    "\n",
    "    LX = copy(LX0)\n",
    "    y = LX - d\n",
    "    fX = 1/2*norm(y)^2\n",
    "    \n",
    "    k = 0\n",
    "    done = false\n",
    "    while !done\n",
    "        \n",
    "        # Compute the search direction dX\n",
    "        Lsy = Ls(y, E)\n",
    "        #evals, evecs = eigs(Lsy, nev=2, which=:SR)\n",
    "        evals, evecs = eigen(Matrix(Lsy))\n",
    "        idx = (abs(evals[1]) > 1e-8) ? 1 : 2\n",
    "\n",
    "        v .= evecs[:,idx]\n",
    "        v .-= mean(v)\n",
    "        v .*= sqrt(τ)/norm(v)\n",
    "        LS = [(v[e[1]] - v[e[2]])^2 for e in E]\n",
    "        LdX = LS - LX\n",
    "\n",
    "        # Update lower bound\n",
    "        \"\"\"\n",
    "        lbnew = fX + dot(Ls(LX - d), dX)\n",
    "              = fX + dot(y, LdX)\n",
    "        \"\"\"\n",
    "\n",
    "        flbnew = fX + dot(y, LdX)\n",
    "        if flbnew > flb\n",
    "            λ = evals[idx]\n",
    "        end\n",
    "        flb = max(flb, flbnew)\n",
    "\n",
    "        # Compute step length\n",
    "        γ = -dot(LdX, y)/norm(LdX)^2\n",
    "        \n",
    "        # Save γ and v to build X\n",
    "        push!(Xinfo[:γ], γ)\n",
    "        push!(Xinfo[:v], copy(v))\n",
    "\n",
    "        # Update X\n",
    "        \"\"\"\n",
    "        LXnew = L(X + γ (S - X))\n",
    "              = LX + γ LdX\n",
    "        \"\"\"\n",
    "\n",
    "        LX .+= γ.*LdX\n",
    "        y .= LX .- d\n",
    "        fX = 1/2*norm(y)^2\n",
    "        \n",
    "        # Update upper bound\n",
    "        fubnew = fX\n",
    "        fub = min(fub, fubnew)\n",
    "\n",
    "        k += 1\n",
    "        \n",
    "        # Check if done\n",
    "        done = (fub - flb0) ≤ α*(flb - flb0)\n",
    "        \n",
    "        if k == 1000\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    @show k\n",
    "    \n",
    "    k, flb, fub, λ, Xinfo\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba0def",
   "metadata": {},
   "outputs": [],
   "source": [
    "τnew = 1.5tr(Xmax)\n",
    "σ = 0.4\n",
    "flb0 = σ^2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "τ = τnew\n",
    "\n",
    "k, flb, fub, λ, Xinfo = FrankWolfe(τ, flb0, dnoisy, E, n)\n",
    "\n",
    "τnew = τ - (flb - flb0)/λ\n",
    "\n",
    "plt1 = plot(legend=:none, xlabel=L\"\\tau\", ylabel=\"error\")\n",
    "plot!(τs, ϕs.^2/2)\n",
    "hline!([σ^2/2])\n",
    "scatter!([tr(Xmax)], [norm(K(Xmax,E) - dnoisy)^2/2], c=2, label=\"Xmax\")\n",
    "plot!([τ, τ], [flb, fub], c=:black, m=:plus, label=:none)\n",
    "plot!(t -> flb + λ*(t - τ), τnew, τ, c=:black, label=:none)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca16ce7d",
   "metadata": {},
   "source": [
    "---\n",
    "# The inexact-Newton algorithm\n",
    "---\n",
    "\n",
    "- We are given an interval $[\\sigma_l, \\sigma_u]$ and seek $\\tau$ such that\n",
    "\n",
    "$$\n",
    "\\frac{1}{2}\\sigma_l^2 \\le h(\\tau) \\le \\frac{1}{2}\\sigma_u^2\n",
    "$$\n",
    "\n",
    "- At iteration $k$ we have $\\tau_k$ such that \n",
    "\n",
    "$$\n",
    "h(\\tau_k) > \\frac{1}{2}\\sigma_l^2\n",
    "$$\n",
    "\n",
    "- We call the Frank-Wolfe method to obtain $l_k$, $u_k$, and $\\lambda_k$\n",
    "\n",
    "$$\n",
    "l_k + \\lambda_k(t - \\tau_k) \\le h(t), \\quad \\forall t\n",
    "$$\n",
    "\n",
    "- We stop if $u_k \\le \\frac{1}{2}\\sigma_u^2$; otherwise we update\n",
    "\n",
    "$$\n",
    "\\tau_{k+1} = \\tau_k - \\frac{1}{\\lambda_k}\\left(l_k - \\frac{1}{2}\\sigma_l^2\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6685838",
   "metadata": {},
   "outputs": [],
   "source": [
    "function inexact_Newton(τ0, σlb, σub, dnoisy, E, n; α=2.0)\n",
    "    τ = τ0\n",
    "\n",
    "    fub = Inf\n",
    "    flb0 = 1/2*σlb^2\n",
    "\n",
    "    k, flb, fub, λ, Xinfo = FrankWolfe(τ, flb0, dnoisy, E, n; α=α)\n",
    "    fwiters = k\n",
    "    \n",
    "    while fub > 1/2*σub^2\n",
    "        @printf(\"τ = %6.2f, ϕ(τ) ∈ [%4.2f,%4.2f]\\n\", \n",
    "            τ, sqrt(2flb), sqrt(2fub))\n",
    "        τ = τ - (flb - flb0)/λ\n",
    "        k, flb, fub, λ, Xinfo = FrankWolfe(τ, flb0, dnoisy, E, n; α=α)\n",
    "        fwiters += k\n",
    "    end\n",
    "\n",
    "    @show fwiters\n",
    "\n",
    "    # Build X\n",
    "    X = zeros(n,n)\n",
    "    for i = 1:length(Xinfo[:γ])\n",
    "        γ = Xinfo[:γ][i]\n",
    "        v = Xinfo[:v][i]\n",
    "        X += γ*(v*v' - X)\n",
    "    end\n",
    "\n",
    "    X\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b1fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "τ0 = n/2\n",
    "σlb, σub = 0.3, 0.4\n",
    "\n",
    "@time X = inexact_Newton(τ0, σlb, σub, dnoisy, E, n)\n",
    "\n",
    "@show tr(X), norm(K(X,E) - dnoisy)\n",
    "\n",
    "plt1 = plot(legend=:topleft, xlabel=L\"\\tau\", ylabel=\"error\")\n",
    "plot!(τs, ϕs, label=L\"\\phi(\\tau)\")\n",
    "hline!([σub], label=\"σub\")\n",
    "hline!([σlb], label=\"σlb\")\n",
    "scatter!([tr(Xmax)], [norm(K(Xmax,E) - dnoisy)], c=2, label=\"Xmax\")\n",
    "scatter!([tr(X)], [norm(K(X,E) - dnoisy)], c=3, label=\"X\")\n",
    "\n",
    "P̄fw = low_rank_soln(X)\n",
    "P̄fw_aligned = align_anchors(A, P̄fw, m)\n",
    "S̄fw_aligned = P̄fw_aligned[1:n-m,:]\n",
    "\n",
    "N = 300\n",
    "@time S̄ = refine(S̄fw_aligned, Strue, N=N)\n",
    "\n",
    "lims=(-0.6, 0.6)\n",
    "plt2 = plot_errors(Ptrue, S̄fw_aligned, m, lims=lims, legend=:none); title!(plt2, \"Inexact Newton\")\n",
    "plt3 = plot_errors(Ptrue, S̄, m, lims=lims, legend=:none); title!(plt3, \"Refined (k=$N)\")\n",
    "plt4 = plot(plt2, plt3, titlefontsize=10)\n",
    "plot(plt1, plt4, layout=(2,1), size=pltsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8a65f3",
   "metadata": {},
   "source": [
    "---\n",
    "# A larger example\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b5908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(2105)\n",
    "\n",
    "R = 0.1\n",
    "\n",
    "n, m, r = 500, 10, 2\n",
    "\n",
    "Strue, A = genprob(n, m, r)\n",
    "\n",
    "Ptrue = [Strue; A]\n",
    "\n",
    "E, dtrue = edges(Ptrue, R, m)\n",
    "\n",
    "@show length(E)\n",
    "\n",
    "plot_network(Ptrue, E, m, plot_edges=false); plot!(size=pltsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72c501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.2\n",
    "\n",
    "dnoisy = add_noise(E, dtrue, p, n, m)\n",
    "\n",
    "ainds = inter_anchor(E, n, m)\n",
    "yinds = ainds .|> !\n",
    "\n",
    "tdy = dtrue[yinds]\n",
    "ndy = dnoisy[yinds]\n",
    "\n",
    "@show p\n",
    "@show std((ndy - tdy)./tdy)\n",
    "@show norm(ndy - tdy)\n",
    "\n",
    "bins = range(0.0, 2R, length=20)\n",
    "plot(legend=:topright, xlabel=\"distance\", ylabel=\"fraction\")\n",
    "histogram!(sqrt.(tdy), bins=bins, alpha=0.5, label=\"noiseless\", normalize=:probability)\n",
    "histogram!(sqrt.(ndy), bins=bins, alpha=0.5, label=\"noisy\", normalize=:probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404792e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a good τ0 by computing bounds\n",
    "τ0 = 150.0\n",
    "k, flb, fub, λ, Xinfo = FrankWolfe(τ0, 0.0, dnoisy, E, n; α=2.0)\n",
    "\n",
    "sqrt(2flb), sqrt(2fub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d24d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "σlb, σub = 0.1, 0.2\n",
    "\n",
    "@time X = inexact_Newton(τ0, σlb, σub, dnoisy, E, n; α=2.0)\n",
    "\n",
    "@show tr(X), norm(K(X,E) - dnoisy);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f28220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "P̄fw = low_rank_soln(X)\n",
    "P̄fw_aligned = align_anchors(A, P̄fw, m)\n",
    "S̄fw_aligned = P̄fw_aligned[1:n-m,:]\n",
    "\n",
    "N = 300\n",
    "@time S̄ = refine(S̄fw_aligned, Strue, N=N);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49184924",
   "metadata": {},
   "outputs": [],
   "source": [
    "lims=(-0.6, 0.6)\n",
    "plt1 = plot_errors(Ptrue, S̄fw_aligned, m, lims=lims, legend=:none); title!(plt1, \"Inexact Newton\")\n",
    "plt2 = plot_errors(Ptrue, S̄, m, lims=lims, legend=:none); title!(plt2, \"Refined (k=$N)\")\n",
    "plot(plt1, plt2, titlefontsize=10, size=(800,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cbc3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c2fb30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701cea78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a3b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e03ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345cbc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b2ab41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e40b2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d601837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89427588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8194e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f1837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8198e609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618feff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5797a84a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb4d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b5442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e719c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301da37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c1cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b95b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67205e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a46b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bebdfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f0d3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
